{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "This is where i will be testing my trained YOLO model on some different manga pages."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from skimage.io import imread, imsave, imshow\n",
    "\n",
    "# Yolo model inladen en klaarzetten voor gebruik\n",
    "net = cv2.dnn.readNet(\"manga_final_weights.weights\", \"manga_final_config.cfg\")  # weight en configuration file ophalen\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Namen van de classes definiÃ«ren (volgorde is zeer belangrijk)\n",
    "classes = [\"RandomFrame\", \"Face\", \"Text\"]\n",
    "def drawboxes(img):\n",
    "    print(img.shape)\n",
    "    height, width, channels = img.shape\n",
    "\n",
    "    # Detecting objects\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    class_ids, confidences, boxes = [], [], []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.3:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                # Rectangle coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    # boxes tekenen\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            confidence = round(confidences[i] * 100, 1)\n",
    "            label = str(classes[int(class_ids[i])])\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color=(211, 44, 44), thickness=3)\n",
    "            cv2.putText(img, str(confidence), (x + 5, y + 30), cv2.FONT_HERSHEY_PLAIN, 2, color=(211, 44, 44), thickness=4)\n",
    "    return img\n",
    "\n",
    "def draw_and_save(files, directory, volume_name):\n",
    "\n",
    "    j = 0\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        if not os.path.exists(f\"Results/{str(volume_name)}\"):\n",
    "            os.makedirs(f\"Results/{str(volume_name)}\")\n",
    "        if not os.path.exists(f\"../../data/test/{volume_name}\"):\n",
    "            os.makedirs(f\"../../data/test/{volume_name}\")\n",
    "        if not os.path.exists(f\"../../data/checking_validity\"):\n",
    "            os.makedirs(f\"../../data/checking_validity/{volume_name}\")\n",
    "\n",
    "        img = cv2.imread(directory + \"/\" +  file)\n",
    "\n",
    "        img = np.array(img)\n",
    "\n",
    "        stacked_img = np.stack((img,)*3, axis=-1)\n",
    "\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        # Detecting objects\n",
    "        blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(output_layers)\n",
    "    \n",
    "        class_ids, confidences, boxes, centers = [], [], [], []\n",
    "\n",
    "        j += 1 \n",
    "\n",
    "        image = Image.fromarray(img)\n",
    "        image.save(f\"../../data/manga109_yolo_faces/{volume_name}{j}.jpg\")\n",
    "        \n",
    "        for out in outs:\n",
    "            \n",
    "            for detection in out:\n",
    "               \n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.3:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    # Rectangle coordinates\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "            \n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "        # boxes tekenen\n",
    "        f = open(f\"../../data/manga109_yolo_faces/{volume_name}{j}.txt\",\"w+\") \n",
    "        for i in range(len(boxes)):\n",
    "            if i in indexes:\n",
    "                x, y, w, h = boxes[i]\n",
    "                confidence = round(confidences[i] * 100, 1)\n",
    "                label = str(classes[int(class_ids[i])])\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), color=(211, 44, 44), thickness=3)\n",
    "                cv2.putText(img, str(confidence), (x + 5, y + 30), cv2.FONT_HERSHEY_PLAIN, 2, color=(211, 44, 44), thickness=4) \n",
    "\n",
    "                w_norm = ((x + w) - x)\n",
    "                h_norm = ((y + h) - y)\n",
    "                x_norm = x + (w/2)\n",
    "                y_norm = y + (h/2)\n",
    "\n",
    "                image2 = image.crop((x, y, x+w, y+h))\n",
    "                image2.save(f\"../../data/checking_validity/{volume_name}{j}.jpg\") \n",
    "                \n",
    "                x_norm = round(x_norm / image.size[0], 6)\n",
    "                y_norm = round(y_norm / image.size[1], 6)\n",
    "                w_norm = round(w_norm / image.size[0], 6)\n",
    "                h_norm = round(h_norm / image.size[1], 6)\n",
    "\n",
    "                f.write(f\"1 {x_norm} {y_norm} {w_norm} {h_norm}\\n\")\n",
    "\n",
    "                \n",
    "        f.close()\n",
    "\n",
    "def Test_Yolo(files, directory, volume_name):\n",
    "    draw_and_save(files, directory, volume_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Which volume of manga would you like to use detection on?\n"
     ]
    }
   ],
   "source": [
    "directory = r'D:\\RESEARCH PROJECT\\Data\\Volumes'\n",
    "files = os.listdir(directory)\n",
    "\n",
    "print(\"Which volume of manga would you like to use detection on?\")\n",
    "for i in range(0, len(files)):\n",
    "    # print(f\" \\t {i}. {files[i]}\")\n",
    "    chosen_volume = i\n",
    "    chosen_directory = directory + \"\\\\\" + str(files[int(chosen_volume)])\n",
    "    Test_Yolo(os.listdir(chosen_directory), chosen_directory,  chosen_directory.partition(\"Volumes\\\\\")[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}